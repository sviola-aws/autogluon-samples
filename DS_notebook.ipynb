{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7f088-3ff1-4396-94c5-54de836fddb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install autogluon --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb2c0d1-7553-467f-a3b9-bf5b677c80f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "In this step we will load .csv file with data we want to use in this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45214df3-4c30-4a43-a102-4a1a56be1cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# loading input data\n",
    "df = pd.read_csv(\"Skyserver_df.csv\")\n",
    "\n",
    "# let's take a look at how our input data looks like\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a01cb02-2ebe-40cf-a7a8-ea0df7e81af7",
   "metadata": {},
   "source": [
    "## 2. Basic data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b17d7a-97a2-4da6-8920-841d2c78b487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3,figsize=(16, 4))\n",
    "ax = sns.distplot(df[df['class']=='STAR'].redshift, bins = 30, ax = axes[0], kde = False)\n",
    "ax.set_title('Star')\n",
    "ax = sns.distplot(df[df['class']=='GALAXY'].redshift, bins = 30, ax = axes[1], kde = False)\n",
    "ax.set_title('Galaxy')\n",
    "ax = sns.distplot(df[df['class']=='QSO'].redshift, bins = 30, ax = axes[2], kde = False)\n",
    "ax = ax.set_title('QSO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cbdd81-82df-4e46-8300-5623756e714d",
   "metadata": {},
   "source": [
    "## 3. Data processing\n",
    "\n",
    "Data processing is a crucial step in building effective machine learning models. This step involves transforming raw data into a format that is suitable for analysis and modeling. It typically includes tasks such as data cleaning, normalization, feature engineering, and data augmentation.\n",
    "\n",
    "Data processing is important because the quality of the data used to train a model can have a significant impact on its accuracy and ability to make accurate predictions. By cleaning and preparing the data, we can remove noise and inconsistencies, and highlight relevant patterns and features that the model can learn from.\n",
    "\n",
    "In this step we will take data processing routine from this notebook and transfer it into our template\n",
    "\n",
    "Below cell contains DS notebook implementation of data processing step and contains following:\n",
    "- clean the data by removing not needed columns\n",
    "- make label encoding of our target column - \"class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9621ac2c-8afd-41d1-aad3-ca5ce3ef0cbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from pickle import dump\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# dropping not needed columns\n",
    "df.drop(['objid', 'run', 'rerun', 'camcol', 'field', 'specobjid'], axis=1, inplace=True)\n",
    "df.head(1)\n",
    "\n",
    "df_temp = df\n",
    "\n",
    "# encode class labels to integers\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(df_temp['class'])\n",
    "df_temp['class'] = y_encoded\n",
    "\n",
    "df = df_temp\n",
    "\n",
    "# split data into train and test part\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('class', axis=1), df['class'], test_size = 0.33)\n",
    "\n",
    "# setting up our target column as first one\n",
    "# For AutoGluon first column of the input data should have the corresponding target variable.\n",
    "# The rest of the columns should have the corresponding predictor variable\n",
    "X_train.insert(0, \"class\", y_train)\n",
    "X_test.insert(0, \"class\", y_test)\n",
    "X_train.to_csv(\"train.csv\", index=False)\n",
    "X_test.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "# saving transformations into s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411803b0-b90c-4cbe-afc6-5305be5f3dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e5b685-c1a8-4295-98c4-ab1b62644f76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07608ae9-f214-4ce0-bdc7-9a2e69b6a0cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = TabularPredictor(label= \"class\").fit(X_train)\n",
    "\n",
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff033a66-01e6-4f5b-b481-9723a6806858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = TabularPredictor(label= \"class\", ).fit(X_train, \n",
    "                                                   presets = [\"high_quality\"]\n",
    "                                                  )\n",
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1e4fb5-5efa-4604-a780-2ed091626786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
